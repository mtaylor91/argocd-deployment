---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: koboldcpp
spec:
  strategy:
    type: Recreate
  template:
    spec:
      containers:
      - name: koboldcpp
        image: images.home.mtaylor.io/koboldcpp:0.0.1
        env:
        - name: MODEL
          value: "/models/Meta-Llama-3-8B-Instruct-Q5_K_M.gguf"
        - name: CONTEXTSIZE
          value: "8000"
        - name: GPULAYERS
          value: "33"
        - name: THREADS
          value: "16"
        ports:
        - containerPort: 8080
          protocol: TCP
        resources:
          limits:
            nvidia.com/gpu: 2
          requests:
            nvidia.com/gpu: 2
        volumeMounts:
        - mountPath: /models
          name: koboldcpp-models
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      volumes:
      - name: koboldcpp-models
        persistentVolumeClaim:
          claimName: koboldcpp-models
